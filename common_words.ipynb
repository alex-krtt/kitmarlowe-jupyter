{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6f2a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T16:32:24.237247Z",
     "start_time": "2023-12-15T16:32:16.785249Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "%pip install spacy\n",
    "\n",
    "if sys.platform.startswith('win'):\n",
    "    os.system('python -m spacy download en_core_web_md')\n",
    "elif sys.platform.startswith('darwin') or sys.platform.startswith('linux'):\n",
    "    os.system('python3 -m spacy download en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e02957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This value controls the number of most common words to display\n",
    "count_of_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012344c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T16:32:30.063260Z",
     "start_time": "2023-12-15T16:32:24.237108Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Common word analysis done for each book individually\n",
    "\n",
    "for file_path in glob.glob(\"books/**/*.txt\", recursive=True):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    nouns = []\n",
    "    adjectives = []\n",
    "    verbs = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\" and not token.is_stop and not token.is_punct and token.lemma_.isalpha() and len(token.lemma_) > 2:\n",
    "            nouns.append(token.text)\n",
    "        elif token.pos_ == \"ADJ\" and not token.is_stop and not token.is_punct and token.lemma_.isalpha() and len(token.lemma_) > 2:\n",
    "            adjectives.append(token.text)\n",
    "        elif token.pos_ == \"VERB\" and not token.is_stop and not token.is_punct and token.lemma_.isalpha() and len(token.lemma_) > 2:\n",
    "            verbs.append(token.text)\n",
    "\n",
    "    nouns_frequency_distribution = Counter(nouns)\n",
    "    adjectives_frequency_distribution = Counter(adjectives)\n",
    "    verbs_frequency_distribution = Counter(verbs)\n",
    "\n",
    "    nouns_most_common = nouns_frequency_distribution.most_common(count_of_words)\n",
    "    adjectives_most_common = adjectives_frequency_distribution.most_common(count_of_words)\n",
    "    verbs_most_common = verbs_frequency_distribution.most_common(count_of_words)\n",
    "\n",
    "    nouns_30_words = []\n",
    "    adjectives_30_words = []\n",
    "    verbs_30_words = []\n",
    "    nouns_30_freq = []\n",
    "    adjectives_30_freq = []\n",
    "    verbs_30_freq = []\n",
    "\n",
    "    for word, freq in nouns_most_common:\n",
    "        nouns_30_words.append(word)\n",
    "        nouns_30_freq.append(freq)\n",
    "\n",
    "    for word, freq in adjectives_most_common:\n",
    "        adjectives_30_words.append(word)\n",
    "        adjectives_30_freq.append(freq)\n",
    "\n",
    "    for word, freq in verbs_most_common:\n",
    "        verbs_30_words.append(word)\n",
    "        verbs_30_freq.append(freq)\n",
    "\n",
    "    print(f\"{count_of_words} most common nouns, adjectives, and verbs for {file_path}\")\n",
    "    plt.figure(figsize=(15, 10))  # sets the figure size to x inches by y inches\n",
    "    plt.bar(nouns_30_words, nouns_30_freq, label=\"Nouns\")\n",
    "    plt.bar(adjectives_30_words, adjectives_30_freq, label=\"Adjectives\")\n",
    "    plt.bar(verbs_30_words, verbs_30_freq, label=\"Verbs\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.title(f\"{count_of_words} most common nouns, adjectives, and verbs for {file_path}\")\n",
    "    plt.xlabel(\"Words\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68629840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_common_words(directory):\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "    nouns_all = []\n",
    "    adjectives_all = []\n",
    "    verbs_all = []\n",
    "\n",
    "    for file_path in glob.glob(directory + \"/*.txt\"):\n",
    "        with open(file_path, \"r\") as file:\n",
    "            text = file.read()\n",
    "\n",
    "        doc = nlp(text)\n",
    "\n",
    "        nouns = []\n",
    "        adjectives = []\n",
    "        verbs = []\n",
    "\n",
    "        for token in doc:\n",
    "            if token.pos_ == \"NOUN\" and not token.is_stop and not token.is_punct and token.lemma_.isalpha() and len(token.lemma_) > 2:\n",
    "                nouns.append(token.text)\n",
    "            elif token.pos_ == \"ADJ\" and not token.is_stop and not token.is_punct and token.lemma_.isalpha() and len(token.lemma_) > 2:\n",
    "                adjectives.append(token.text)\n",
    "            elif token.pos_ == \"VERB\" and not token.is_stop and not token.is_punct and token.lemma_.isalpha() and len(token.lemma_) > 2:\n",
    "                verbs.append(token.text)\n",
    "\n",
    "        nouns_all.extend(nouns)\n",
    "        adjectives_all.extend(adjectives)\n",
    "        verbs_all.extend(verbs)\n",
    "\n",
    "    nouns_fd = Counter(nouns_all)\n",
    "    adjectives_fd = Counter(adjectives_all)\n",
    "    verbs_fd = Counter(verbs_all)\n",
    "\n",
    "    count_of_words = 20\n",
    "\n",
    "    nouns_30 = nouns_fd.most_common(count_of_words)\n",
    "    adjectives_30 = adjectives_fd.most_common(count_of_words)\n",
    "    verbs_30 = verbs_fd.most_common(count_of_words)\n",
    "\n",
    "    nouns_30_words = []\n",
    "    adjectives_30_words = []\n",
    "    verbs_30_words = []\n",
    "    nouns_30_freq = []\n",
    "    adjectives_30_freq = []\n",
    "    verbs_30_freq = []\n",
    "\n",
    "    for word, freq in nouns_30:\n",
    "        nouns_30_words.append(word)\n",
    "        nouns_30_freq.append(freq)\n",
    "\n",
    "    for word, freq in adjectives_30:\n",
    "        adjectives_30_words.append(word)\n",
    "        adjectives_30_freq.append(freq)\n",
    "\n",
    "    for word, freq in verbs_30:\n",
    "        verbs_30_words.append(word)\n",
    "        verbs_30_freq.append(freq)\n",
    "\n",
    "    print(f\"{count_of_words} most common nouns, adjectives, and verbs in the {directory} corpus\")\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.bar(nouns_30_words, nouns_30_freq, label=\"Nouns\")\n",
    "    plt.bar(adjectives_30_words, adjectives_30_freq, label=\"Adjectives\")\n",
    "    plt.bar(verbs_30_words, verbs_30_freq, label=\"Verbs\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.title(f\"{count_of_words} most common nouns, adjectives, and verbs in the {directory} corpus\")\n",
    "    plt.xlabel(\"Words\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "# Common words plot for each corpus as a whole\n",
    "\n",
    "plot_common_words(\"books/Shakespeare-corpus\")\n",
    "plot_common_words(\"books/Marlowe-corpus\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

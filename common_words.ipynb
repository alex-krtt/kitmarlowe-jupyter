{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f6b7617",
   "metadata": {},
   "source": [
    "# Most Common Adjective, Verb and Noun Graph\n",
    "## Dependency Installation and Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012344c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T16:32:30.063260Z",
     "start_time": "2023-12-15T16:32:24.237108Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install spacy matplotlib pandas seaborn pyarrow\n",
    "\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "if sys.platform.startswith('win'):\n",
    "    os.system('python -m spacy download en_core_web_sm')\n",
    "elif sys.platform.startswith('darwin') or sys.platform.startswith('linux'):\n",
    "    os.system('python3 -m spacy download en_core_web_sm')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d07041",
   "metadata": {},
   "source": [
    "### Change the count_of_words to get the top n words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e02957",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_of_words = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbbc579",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4ad67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_common_words_file(file_path):\n",
    "    # Initialize empty lists to store words\n",
    "    nouns = []\n",
    "    adjectives = []\n",
    "    verbs = []\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        text = file.read()\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Extract and filter nouns, adjectives, and verbs\n",
    "        for token in doc:\n",
    "            if token.pos_ == \"NOUN\" and not token.is_stop and not token.is_punct and token.lemma_.isalpha() and len(token.lemma_) > 2:\n",
    "                nouns.append(token.text)\n",
    "            elif token.pos_ == \"ADJ\" and not token.is_stop and not token.is_punct and token.lemma_.isalpha() and len(token.lemma_) > 2:\n",
    "                adjectives.append(token.text)\n",
    "            elif token.pos_ == \"VERB\" and not token.is_stop and not token.is_punct and token.lemma_.isalpha() and len(token.lemma_) > 2:\n",
    "                verbs.append(token.text)\n",
    "\n",
    "    # Count the frequency of each word\n",
    "    nouns_fd = Counter(nouns)\n",
    "    adjectives_fd = Counter(adjectives)\n",
    "    verbs_fd = Counter(verbs)\n",
    "\n",
    "    # Get the top 30 most frequent words\n",
    "    nouns_30 = nouns_fd.most_common(count_of_words)\n",
    "    adjectives_30 = adjectives_fd.most_common(count_of_words)\n",
    "    verbs_30 = verbs_fd.most_common(count_of_words)\n",
    "\n",
    "    # Create a DataFrame with the top 30 words and their frequencies\n",
    "    df = pd.DataFrame({'Nouns': [word for word, freq in nouns_30], 'Nouns Frequency': [freq for word, freq in nouns_30],\n",
    "                       'Adjectives': [word for word, freq in adjectives_30], 'Adjectives Frequency': [freq for word, freq in adjectives_30],\n",
    "                       'Verbs': [word for word, freq in verbs_30], 'Verbs Frequency': [freq for word, freq in verbs_30]})\n",
    "\n",
    "    # Plot the bar charts\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "    sns.barplot(x='Nouns Frequency', y='Nouns', data=df, ax=axes[0], palette=\"Blues_d\")\n",
    "    axes[0].set_title(f\"Top {count_of_words} Nouns\")\n",
    "    axes[0].set_xlabel(\"Frequency\")\n",
    "\n",
    "    sns.barplot(x='Adjectives Frequency', y='Adjectives', data=df, ax=axes[1], palette=\"Greens_d\")\n",
    "    axes[1].set_title(f\"Top {count_of_words} Adjectives\")\n",
    "    axes[1].set_xlabel(\"Frequency\")\n",
    "\n",
    "    sns.barplot(x='Verbs Frequency', y='Verbs', data=df, ax=axes[2], palette=\"Reds_d\")\n",
    "    axes[2].set_title(f\"Top {count_of_words} verbs\")\n",
    "    axes[2].set_xlabel(\"Frequency\")\n",
    "\n",
    "    fig.suptitle(f\"Top {count_of_words} Words in the Book: \\\"{file_path.rsplit('/', 1)[-1].rsplit('.', 1)[0]}\\\"\", fontweight=\"bold\", fontsize=16)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_common_words_corpus(directory):\n",
    "    # Initialize empty lists to store words\n",
    "    nouns = []\n",
    "    adjectives = []\n",
    "    verbs = []\n",
    "\n",
    "    # Read and process each text file in the directory\n",
    "    for file_path in glob.glob(directory + \"/*.txt\"):\n",
    "        with open(file_path, \"r\") as file:\n",
    "            text = file.read()\n",
    "\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Extract and filter nouns, adjectives, and verbs\n",
    "        for token in doc:\n",
    "            if token.pos_ == \"NOUN\" and not token.is_stop and not token.is_punct and token.lemma_.isalpha() and len(token.lemma_) > 2:\n",
    "                nouns.append(token.text)\n",
    "            elif token.pos_ == \"ADJ\" and not token.is_stop and not token.is_punct and token.lemma_.isalpha() and len(token.lemma_) > 2:\n",
    "                adjectives.append(token.text)\n",
    "            elif token.pos_ == \"VERB\" and not token.is_stop and not token.is_punct and token.lemma_.isalpha() and len(token.lemma_) > 2:\n",
    "                verbs.append(token.text)\n",
    "\n",
    "    # Count the frequency of each word\n",
    "    nouns_fd = Counter(nouns)\n",
    "    adjectives_fd = Counter(adjectives)\n",
    "    verbs_fd = Counter(verbs)\n",
    "\n",
    "    # Get the top 30 most frequent words\n",
    "    nouns_30 = nouns_fd.most_common(count_of_words)\n",
    "    adjectives_30 = adjectives_fd.most_common(count_of_words)\n",
    "    verbs_30 = verbs_fd.most_common(count_of_words)\n",
    "\n",
    "    # Create a DataFrame with the top 30 words and their frequencies\n",
    "    df = pd.DataFrame({'Nouns': [word for word, freq in nouns_30], 'Nouns Frequency': [freq for word, freq in nouns_30],\n",
    "                       'Adjectives': [word for word, freq in adjectives_30], 'Adjectives Frequency': [freq for word, freq in adjectives_30],\n",
    "                       'Verbs': [word for word, freq in verbs_30], 'Verbs Frequency': [freq for word, freq in verbs_30]})\n",
    "\n",
    "    # Plot the bar charts\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "    sns.barplot(x='Nouns Frequency', y='Nouns', data=df, ax=axes[0], palette=\"Blues_d\")\n",
    "    axes[0].set_title(f\"Top {count_of_words} Nouns\")\n",
    "    axes[0].set_xlabel(\"Frequency\")\n",
    "\n",
    "    sns.barplot(x='Adjectives Frequency', y='Adjectives', data=df, ax=axes[1], palette=\"Greens_d\")\n",
    "    axes[1].set_title(f\"Top {count_of_words} Adjectives\")\n",
    "    axes[1].set_xlabel(\"Frequency\")\n",
    "\n",
    "    sns.barplot(x='Verbs Frequency', y='Verbs', data=df, ax=axes[2], palette=\"Reds_d\")\n",
    "    axes[2].set_title(f\"Top {count_of_words} verbs\")\n",
    "    axes[2].set_xlabel(\"Frequency\")\n",
    "    fig.suptitle(f\"Top {count_of_words} Words in \\\"{directory}\\\" Corpus\", fontweight=\"bold\", fontsize=16)\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a4953",
   "metadata": {},
   "source": [
    "## Running the code\n",
    "\n",
    "The `plot_common_words_corpus(directory)` function analyzes a corpus of text files located in the specified directory. It identifies the most common words across all the files and plots their frequencies. This function is useful when you want to understand the most frequently used words in a large set of documents.\n",
    "\n",
    "The `plot_common_words_file(file_path)` function, on the other hand, analyzes a single text file at the given file path. It identifies the most common words in that file and plots their frequencies. This function is useful when you want to understand the most frequently used words in a specific document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0fc6f8",
   "metadata": {},
   "source": [
    "Here are a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e41e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_common_words_file(\"books/Shakespeare-corpus/Ado: Much Ado About Nothing.txt\")\n",
    "plot_common_words_file(\"books/Shakespeare-corpus/1H4: Henry IV, Part 1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2230733",
   "metadata": {},
   "source": [
    "#### Uncomment the following lines to get Shakespeare's and Marlowe's most common words from the corpus as a whole\n",
    "Any line that starts with a # is ignored the computer\n",
    "The Shakespeare/Marlowe corpus may take a long time to execute so I commented them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccdd66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_common_words_corpus(\"books/Shakespeare-corpus\")\n",
    "#plot_common_words_corpus(\"books/Marlowe-corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224ed146",
   "metadata": {},
   "source": [
    "#### On the other hand, the following will generate a graph for every single file found under the Shakespeare or Marlowe corpora\n",
    "Any line that starts with a # is ignored the computer\n",
    "The Shakespeare/Marlowe corpus may take a long time to execute so I commented them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddebc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in glob.glob(\"books/Shakespeare-corpus/*.txt\"): plot_common_words_file(file)\n",
    "# for file in glob.glob(\"books/Marlowe-corpus/*.txt\"): plot_common_words_file(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b61c9",
   "metadata": {},
   "source": [
    "### Custom Corpus\n",
    "To run this code simply uncomment the following line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12182c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_common_words_corpus(\"books/custom-corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a92cad",
   "metadata": {},
   "source": [
    "The following block was left empty so you may experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57dfcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
